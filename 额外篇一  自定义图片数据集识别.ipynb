{"cells":[{"metadata":{"id":"BE257206C1584EB883F2DC73A0CBE1A5","mdEditEnable":false},"cell_type":"markdown","source":"# 前言\n中央民族大学创业团队巨神人工智能科技在科赛网公开了一个TibetanMNIST正是形体藏文中的数字数据集，TibetanMNIST数据集的原图片中，图片的大小是`350*350`的黑白图片，图片文件名称的第一个数字就是图片的标签，如`0_10_398.jpg`这张图片代表的就是藏文的数字0。在本项目中我们结合第四章所学的卷积神经网络，来完成TibetanMNIST数据集的分类识别。"},{"metadata":{"id":"06D5C525D0114A40A0E90D0CBC5D1BA3","mdEditEnable":false},"cell_type":"markdown","source":"# 安装PaddlePaddle"},{"metadata":{"id":"AD7AE60D0DBC4A6191CA141FA84A4380","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\nRequirement already satisfied: paddlepaddle==1.1.0 in /opt/conda/lib/python3.5/site-packages (1.1.0)\nRequirement already satisfied: matplotlib==2.2.3 in /opt/conda/lib/python3.5/site-packages (from paddlepaddle==1.1.0) (2.2.3)\nRequirement already satisfied: scipy>=0.19.0 in /opt/conda/lib/python3.5/site-packages (from paddlepaddle==1.1.0) (1.0.0)\nRequirement already satisfied: rarfile in /opt/conda/lib/python3.5/site-packages (from paddlepaddle==1.1.0) (3.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.5/site-packages (from paddlepaddle==1.1.0) (1.11.0)\nRequirement already satisfied: requests==2.9.2 in /opt/conda/lib/python3.5/site-packages (from paddlepaddle==1.1.0) (2.9.2)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.5/site-packages (from paddlepaddle==1.1.0) (4.2.1)\nRequirement already satisfied: protobuf==3.1 in /opt/conda/lib/python3.5/site-packages (from paddlepaddle==1.1.0) (3.1.0)\nRequirement already satisfied: numpy<=1.14,>=1.12 in /opt/conda/lib/python3.5/site-packages (from paddlepaddle==1.1.0) (1.14.0)\nRequirement already satisfied: opencv-python in /opt/conda/lib/python3.5/site-packages (from paddlepaddle==1.1.0) (3.4.3.18)\nRequirement already satisfied: nltk>=3.2.2 in /opt/conda/lib/python3.5/site-packages (from paddlepaddle==1.1.0) (3.3)\nRequirement already satisfied: recordio>=0.1.0 in /opt/conda/lib/python3.5/site-packages (from paddlepaddle==1.1.0) (0.1.7)\nRequirement already satisfied: graphviz in /opt/conda/lib/python3.5/site-packages (from paddlepaddle==1.1.0) (0.8.4)\nRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.5/site-packages (from matplotlib==2.2.3->paddlepaddle==1.1.0) (2.7.3)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.5/site-packages (from matplotlib==2.2.3->paddlepaddle==1.1.0) (2.1.10)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.5/site-packages (from matplotlib==2.2.3->paddlepaddle==1.1.0) (1.0.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.5/site-packages (from matplotlib==2.2.3->paddlepaddle==1.1.0) (0.10.0)\nRequirement already satisfied: pytz in /opt/conda/lib/python3.5/site-packages (from matplotlib==2.2.3->paddlepaddle==1.1.0) (2018.5)\nRequirement already satisfied: olefile in /opt/conda/lib/python3.5/site-packages (from Pillow->paddlepaddle==1.1.0) (0.46)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.5/site-packages/setuptools-27.2.0-py3.5.egg (from protobuf==3.1->paddlepaddle==1.1.0) (27.2.0)\n\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}],"source":"!pip install paddlepaddle==1.1.0 -i https://mirrors.aliyun.com/pypi/simple/","execution_count":1},{"metadata":{"id":"F2BA17D4F1484A018B1F9E15D4CA69AD","mdEditEnable":false},"cell_type":"markdown","source":"# 导入所需的包\n主要是使用到PaddlePaddle的fluid和paddle依赖库，cpu_count库是获取当前CPU的数量的，matplotlib用于展示图片。"},{"cell_type":"code","execution_count":22,"metadata":{"id":"3E41B5D110B548F68721AC7A496B51E4","collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.5/site-packages/matplotlib/font_manager.py:281: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n  'Matplotlib is building the font cache using fc-list. '\n","name":"stderr"}],"source":"import paddle.fluid as fluid\nimport paddle\nimport numpy as np\nfrom PIL import Image\nimport os\nfrom multiprocessing import cpu_count\nimport matplotlib.pyplot as plt"},{"cell_type":"markdown","metadata":{"id":"395C6D6075F64AFF8B82908D06A31AA8","mdEditEnable":false},"source":"# 生成图像列表\n因为TibetanMNIST数据集已经在科赛网发布了，所以我们创建项目的时候直接挂载就可以了，数据集标题为`【首发活动】TibetanMNIST藏文手写数字数据集`。\n\n挂载数据集之后，TibetanMNIST的原图像文件存放在以下目录，我们可以在以下目录读取全部的图片文件。"},{"cell_type":"code","execution_count":3,"metadata":{"id":"7A590A8E03754C418289378D87CB08B4","collapsed":false,"scrolled":false},"outputs":[],"source":"data_path = '/home/kesci/input/TibetanMNIST5610/TibetanMNIST/TibetanMNIST/'\ndata_imgs = os.listdir(data_path)"},{"metadata":{"id":"149927F7256145878CF7C2417DFCA9E8","mdEditEnable":false},"cell_type":"markdown","source":"获取全部的图片路径之后，我们就生成一个图像列表，这个列表文件包括图片的绝对路径和图片对于的label，中间用制表符分开。格式如下，其中有一个`lable.txt`的文本文件，我们要忽略它，否则在读取的时候就报错。\n\n```\n/home/kesci/input/TibetanMNIST5610/TibetanMNIST/TibetanMNIST/8_2_1.jpg\t8\n/home/kesci/input/TibetanMNIST5610/TibetanMNIST/TibetanMNIST/0_11_264.jpg\t0\n/home/kesci/input/TibetanMNIST5610/TibetanMNIST/TibetanMNIST/0_13_320.jpg\t0\n/home/kesci/input/TibetanMNIST5610/TibetanMNIST/TibetanMNIST/3_16_193.jpg\t3\n```"},{"cell_type":"code","execution_count":4,"metadata":{"id":"1D2D5472C52D44C6820E3D0981152DB1","collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"图像列表已生成。\n","name":"stdout"}],"source":"with open('./train_data.list', 'w') as f_train:\n    with open('./test_data.list', 'w') as f_test:\n        for i in range(len(data_imgs)):\n            if data_imgs[i] == 'lable.txt':\n                continue\n            if i % 10 == 0:\n                f_test.write(os.path.join(data_path, data_imgs[i]) + \"\\t\" + data_imgs[i][0:1] + '\\n')\n            else:\n                f_train.write(os.path.join(data_path, data_imgs[i]) + \"\\t\" + data_imgs[i][0:1] + '\\n')\n        print('图像列表已生成。')"},{"cell_type":"markdown","metadata":{"id":"DCA3E7A35ED24C1DBE5758B8556BE3D3","mdEditEnable":false},"source":"# 定义读取数据\nPaddlePaddle读取训练和测试数据都是通过reader来读取的，所以我们要自定义一个reader。首先我们定义一个`train_mapper()`函数，这个函数是对图片进行预处理的，比如通过`paddle.dataset.image.simple_transform`接口对图片进行压缩然后裁剪，和灰度化，当参数`is_train`为True时就会随机裁剪，否则为中心裁剪，一般测试和预测都是中心裁剪。`train_r()`函数是从上一部分生成的图像列表中读取图片路径和标签，然后把图片路径传递给`train_mapper()`函数进行预处理。同样的测试数据也是相同的操作。"},{"cell_type":"code","execution_count":6,"metadata":{"id":"6C67723990A6424B8A8CDF084A1B8B93","collapsed":false,"scrolled":false},"outputs":[],"source":"def train_mapper(sample):\n    img, label = sample\n    img = paddle.dataset.image.load_image(file=img, is_color=False)\n    img = paddle.dataset.image.simple_transform(im=img, resize_size=32, crop_size=28, is_color=False, is_train=True)\n    img = img.flatten().astype('float32') / 255.0\n    return img, label\n    \ndef train_r(train_list_path):\n    def reader():\n        with open(train_list_path, 'r') as f:\n            lines = f.readlines()\n            del lines[len(lines)-1]\n            for line in lines:\n                img, label = line.split('\\t')\n                yield img, int(label)\n    return paddle.reader.xmap_readers(train_mapper, reader, cpu_count(), 1024)\n\ndef test_mapper(sample):\n    img, label = sample\n    img = paddle.dataset.image.load_image(file=img, is_color=False)\n    img = paddle.dataset.image.simple_transform(im=img, resize_size=32, crop_size=28, is_color=False, is_train=False)\n    img = img.flatten().astype('float32') / 255.0\n    return img, label\n    \ndef test_r(test_list_path):\n    def reader():\n        with open(test_list_path, 'r') as f:\n            lines = f.readlines()\n            for line in lines:\n                img, label = line.split('\\t')\n                yield img, int(label)\n    return paddle.reader.xmap_readers(test_mapper, reader, cpu_count(), 1024)"},{"cell_type":"markdown","metadata":{"id":"5DBF912E4F3842C0841E86B4143A26DA","mdEditEnable":false},"source":"# 定义卷积神经网络\n这里定义了一个卷积神经网络，读者可用根据自己的情况修改或更换其他卷积神经网络。"},{"cell_type":"code","execution_count":7,"metadata":{"id":"3F416578FBC74749923ACFC4E4C40F2E","collapsed":false,"scrolled":false},"outputs":[],"source":"def cnn(ipt):\n    conv1 = fluid.layers.conv2d(input=ipt, \n                                num_filters=32, \n                                filter_size=3, \n                                padding=1, \n                                stride=1, \n                                name='conv1', \n                                act='relu')\n    \n    pool1 = fluid.layers.pool2d(input=conv1, \n                                pool_size=2, \n                                pool_stride=2, \n                                pool_type='max', \n                                name='pool1')\n    \n    bn1 = fluid.layers.batch_norm(input=pool1, name='bn1')\n    \n    conv2 = fluid.layers.conv2d(input=bn1, \n                                num_filters=64, \n                                filter_size=3, \n                                padding=1, \n                                stride=1, \n                                name='conv2', \n                                act='relu')\n    \n    pool2 = fluid.layers.pool2d(input=conv2, \n                                pool_size=2, \n                                pool_stride=2,\n                                pool_type='max', \n                                name='pool2')\n    \n    bn2 = fluid.layers.batch_norm(input=pool2, name='bn2')\n    \n    fc1 = fluid.layers.fc(input=bn2, size=1024, act='relu', name='fc1')\n    \n    fc2 = fluid.layers.fc(input=fc1, size=10, act='softmax', name='fc2')\n    \n    return fc2"},{"cell_type":"markdown","metadata":{"id":"AAA371FCF14D4CC8886CAAFC3E3E7220","mdEditEnable":false},"source":"# 获取网络\n通过上面定义的卷积神经网络获取一个分类器，网络的输入层是通过`fluid.layers.data`接口定义的，输入的形状为`[1, 28, 28]`，表示为单通道，宽度和高度都是28的灰度图。"},{"cell_type":"code","execution_count":8,"metadata":{"id":"CFDA7C76FAFF4C948CC8F9BB66C00328","collapsed":false,"scrolled":false},"outputs":[],"source":"image = fluid.layers.data(name='image', shape=[1, 28, 28], dtype='float32')\nnet = cnn(image)"},{"cell_type":"markdown","metadata":{"id":"98191AE5E5CE4A7080EE080AA81589F2","mdEditEnable":false},"source":"# 定义损失函数\n这里使用了交叉熵损失函数`fluid.layers.cross_entropy`，还使用了`fluid.layers.accuracy`接口，方便在训练和测试的是输出平均值。"},{"cell_type":"code","execution_count":9,"metadata":{"id":"BB358DE27AEB46AC88DAB6029BE022A8","collapsed":false,"scrolled":false},"outputs":[],"source":"label = fluid.layers.data(name='label', shape=[1], dtype='int64')\ncost = fluid.layers.cross_entropy(input=net, label=label)\navg_cost = fluid.layers.mean(x=cost)\nacc = fluid.layers.accuracy(input=net, label=label, k=1)"},{"cell_type":"markdown","metadata":{"id":"A495805EFDAB4956B4BA0E061307D815","mdEditEnable":false},"source":"# 克隆测试程序\n在定义损失之后和定义优化方法之前从主程序中克隆一个测试程序。"},{"cell_type":"code","execution_count":10,"metadata":{"id":"988CE6D5CD624AFAA032F11E1EAE08BA","collapsed":false,"scrolled":false},"outputs":[],"source":"test_program = fluid.default_main_program().clone(for_test=True)"},{"cell_type":"markdown","metadata":{"id":"1546115586A8443E8DB64CB58AFB8DAC","mdEditEnable":false},"source":"# 定义优化方法\n接着是定义优化方法，这里使用的是Adam优化方法，读取也可用使用其他的优化方法。"},{"cell_type":"code","execution_count":11,"metadata":{"id":"AD77EFE5B7EE47978AF360029D3BF073","collapsed":false,"scrolled":false},"outputs":[],"source":"optimizer = fluid.optimizer.AdamOptimizer(learning_rate=0.001)\nopt = optimizer.minimize(avg_cost)"},{"cell_type":"markdown","metadata":{"id":"14ACF3DB6B9C4226A88A6C56482820CC","mdEditEnable":false},"source":"# 创建执行器\n这里是创建执行器，并指定使用CPU执行训练。"},{"cell_type":"code","execution_count":12,"metadata":{"id":"3A08628C3F98437ABE36ECBB0939DEA3","collapsed":false,"scrolled":false},"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"[]"}}],"source":"place = fluid.CPUPlace()\nexe = fluid.Executor(place=place)\nexe.run(program=fluid.default_startup_program())"},{"cell_type":"markdown","metadata":{"id":"D14A7E1F53F94C3E86FFF7202D27ACD3","mdEditEnable":false},"source":"# 把图片数据生成reader\n把上面定义的reader按照设置的大小得到每一个batch的reader。"},{"cell_type":"code","execution_count":13,"metadata":{"id":"4941141D046843C3957152745CDF8EFD","collapsed":false,"scrolled":false},"outputs":[],"source":"train_reader = paddle.batch(reader=paddle.reader.shuffle(reader=train_r('./train_data.list'), buf_size=3000), batch_size=128)\ntest_reader = paddle.batch(reader=test_r('./test_data.list'), batch_size=128)"},{"cell_type":"markdown","metadata":{"id":"0F97528A1A8449D68C2585A25579F96E","mdEditEnable":false},"source":"# 定义输入数据的维度\n定义输入数据的维度，第一个是图片数据，第二个是图片对应的标签。"},{"cell_type":"code","execution_count":14,"metadata":{"id":"AB85905AA91C492E871E74AE09282B62","collapsed":false,"scrolled":false},"outputs":[],"source":"feeder = fluid.DataFeeder(place=place, feed_list=[image, label])"},{"cell_type":"markdown","metadata":{"id":"CE75798DD2F34D6AB6280D9730CFF02B","mdEditEnable":false},"source":"# 开始训练\n开始执行训练，这里只是训练10个Pass，读者可以随意设置。我们在每一个Pass训练完成之后，都进行使用测试数据集测试模型的准确率和报错一次预测模型。"},{"cell_type":"code","execution_count":15,"metadata":{"id":"097D828175BD4707B91FDE92428D39F4","collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"\nPass：0, Batch：0, Cost：2.971555, Accuracy：0.101562\n...................................................................................................\nPass：0, Batch：100, Cost：0.509201, Accuracy：0.859375\n........................\nTest：0, Cost：0.255964, Accuracy：0.928092\n\nPass：1, Batch：0, Cost：0.383406, Accuracy：0.882812\n...................................................................................................\nPass：1, Batch：100, Cost：0.262583, Accuracy：0.906250\n........................\nTest：1, Cost：0.210227, Accuracy：0.942152\n\nPass：2, Batch：0, Cost：0.248821, Accuracy：0.921875\n...................................................................................................\nPass：2, Batch：100, Cost：0.121569, Accuracy：0.953125\n........................\nTest：2, Cost：0.147000, Accuracy：0.959041\n\nPass：3, Batch：0, Cost：0.219034, Accuracy：0.914062\n...................................................................................................\nPass：3, Batch：100, Cost：0.149375, Accuracy：0.929688\n........................\nTest：3, Cost：0.135075, Accuracy：0.967970\n\nPass：4, Batch：0, Cost：0.097395, Accuracy：0.960938\n...................................................................................................\nPass：4, Batch：100, Cost：0.088472, Accuracy：0.976562\n........................\nTest：4, Cost：0.130905, Accuracy：0.965254\n\nPass：5, Batch：0, Cost：0.115069, Accuracy：0.960938\n...................................................................................................\nPass：5, Batch：100, Cost：0.132130, Accuracy：0.953125\n........................\nTest：5, Cost：0.123031, Accuracy：0.969086\n\nPass：6, Batch：0, Cost：0.083716, Accuracy：0.984375\n...................................................................................................\nPass：6, Batch：100, Cost：0.093365, Accuracy：0.968750\n........................\nTest：6, Cost：0.113957, Accuracy：0.970686\n\nPass：7, Batch：0, Cost：0.062250, Accuracy：0.976562\n...................................................................................................\nPass：7, Batch：100, Cost：0.095572, Accuracy：0.968750\n........................\nTest：7, Cost：0.097893, Accuracy：0.974182\n\nPass：8, Batch：0, Cost：0.122696, Accuracy：0.960938\n...................................................................................................\nPass：8, Batch：100, Cost：0.154212, Accuracy：0.976562\n........................\nTest：8, Cost：0.095770, Accuracy：0.969570\n\nPass：9, Batch：0, Cost：0.105826, Accuracy：0.960938\n...................................................................................................\nPass：9, Batch：100, Cost：0.125963, Accuracy：0.976562\n........................\nTest：9, Cost：0.078607, Accuracy：0.973550\n","name":"stdout"}],"source":"for pass_id in range(10):\n    for batch_id, data in enumerate(train_reader()):\n        train_cost, train_acc = exe.run(program=fluid.default_main_program(), \n                                        feed=feeder.feed(data), \n                                        fetch_list=[avg_cost, acc])\n        if batch_id % 100 == 0:\n            print('\\nPass：%d, Batch：%d, Cost：%f, Accuracy：%f' % (pass_id, batch_id, train_cost[0], train_acc[0]))\n        else:\n            print('.', end=\"\")\n    \n    test_costs = []\n    test_accs = []\n    for batch_id, data in enumerate(test_reader()):\n        test_cost, test_acc = exe.run(program=test_program, \n                                      feed=feeder.feed(data),\n                                      fetch_list=[avg_cost, acc])\n        test_costs.append(test_cost[0])\n        test_accs.append(test_acc[0])\n    test_cost = sum(test_costs) / len(test_costs)\n    test_acc = sum(test_accs) / len(test_accs)\n    print('\\nTest：%d, Cost：%f, Accuracy：%f' % (pass_id, test_cost, test_acc))\n    \n    fluid.io.save_inference_model(dirname='./model', feeded_var_names=['image'], target_vars=[net], executor=exe)"},{"cell_type":"markdown","metadata":{"id":"07F180FD997749908E1152956F0F5A39","mdEditEnable":false},"source":"# 获取预测程序\n通过上面保存的预测模型，我们可用生成预测程序，并用于图片预测。"},{"cell_type":"code","execution_count":16,"metadata":{"id":"FE78A0BEA8784BE58F513AB6A91F3E37","collapsed":false,"scrolled":false},"outputs":[],"source":"[infer_program, feeded_var_names, target_vars] = fluid.io.load_inference_model(dirname='./model', executor=exe)"},{"cell_type":"markdown","metadata":{"id":"0CD1CF8DFB4C49FC8337EC9DE6044AA7","mdEditEnable":false},"source":"# 进行数据预处理\n在对图片进行预测之前，还需要对图片进行预处理。"},{"cell_type":"code","execution_count":17,"metadata":{"id":"E074665EFA7F4798861E6713A79BB92F","collapsed":false,"scrolled":false},"outputs":[],"source":"def load_image(path):\n    img = paddle.dataset.image.load_image(file=path, is_color=False)\n    img = paddle.dataset.image.simple_transform(im=img, resize_size=32, crop_size=28, is_color=False, is_train=False)\n    img = img.astype('float32')\n    img = img[np.newaxis, ] / 255.0\n    return img"},{"cell_type":"markdown","metadata":{"id":"FE060F7FD2DB46D0A5A049247B60523B","mdEditEnable":false},"source":"# 获取预测图片\n然后把与处理后的图片加入到列表中，可用多张图片一起预测的。然后转换成numpy的类型。"},{"cell_type":"code","execution_count":18,"metadata":{"id":"34857F552D54422C854BEC6D83EDBC3E","collapsed":false,"scrolled":false},"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"(1, 1, 28, 28)"}}],"source":"infer_imgs = []\ninfer_imgs.append(load_image('/home/kesci/input/TibetanMNIST5610/TibetanMNIST/TibetanMNIST/0_10_398.jpg'))\ninfer_imgs = np.array(infer_imgs)\ninfer_imgs.shape"},{"cell_type":"markdown","metadata":{"id":"1F4765B046F047638EC9B58A19CF0348","mdEditEnable":false},"source":"# 执行预测\n最后执行预测，输入的数据通过`feed`参数传入，得到一个预测结果，这个结果是每个类别的概率。"},{"cell_type":"code","execution_count":19,"metadata":{"id":"625D8ED7B80242C98B6EAE05C2CC0EF0","collapsed":false,"scrolled":false},"outputs":[],"source":"result = exe.run(program=infer_program, \n                 feed={feeded_var_names[0]:infer_imgs}, \n                 fetch_list=target_vars)"},{"cell_type":"markdown","metadata":{"id":"C71760B6393B44F29DA327D62C3584A3","mdEditEnable":true},"source":"# 解析结果，获取概率最大的label\n我们对输出的结果转换一下，把概率最大的label输出，同时输出当前预测的图片。"},{"cell_type":"code","execution_count":20,"metadata":{"id":"7AA7766A79B3476C8D136B0234D28F98","collapsed":false,"scrolled":false},"outputs":[],"source":"lab = np.argsort(result)"},{"cell_type":"code","execution_count":26,"metadata":{"id":"6EE2A177BCAD4310A56B5A6AC7D1150B","collapsed":false,"scrolled":false},"outputs":[{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"text/plain":"<Figure size 432x288 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/rt_upload/6EE2A177BCAD4310A56B5A6AC7D1150B/pj8u2w345y.png\">"}},{"output_type":"stream","text":"预测结果为：0\n","name":"stdout"}],"source":"im = Image.open('/home/kesci/input/TibetanMNIST5610/TibetanMNIST/TibetanMNIST/0_10_398.jpg')\nplt.imshow(im)\nplt.show()\n\nprint('预测结果为：%d' % lab[0][0][-1])"},{"metadata":{"id":"0E542B5C8AEE45FC8B077B62D22F1C3F","collapsed":false,"scrolled":false,"mdEditEnable":true},"cell_type":"markdown","source":"到处为止，本章就结束了。本章是一个额外篇，通过学习本章可以学习如果使用卷积神经网络训练自己的图像数据集。\n\n同步到CSDN博客：https://blog.csdn.net/qq_33200967/article/details/84847519\n\n项目代码GitHub地址：https://github.com/yeyupiaoling/LearnPaddle2/tree/master/extra1\n\n本文章由夜雨飘零制作\n\n#  参考资料\n 1. https://www.kesci.com/home/dataset/5bfe734a954d6e0010683839\n 2. https://blog.csdn.net/qq_33200967/article/details/83506694"},{"metadata":{"id":"6F9716A294A8446B84C94D44080B4FE1"},"cell_type":"code","outputs":[],"source":"","execution_count":null}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3},"version":"3.5.5","pygments_lexer":"ipython3","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}